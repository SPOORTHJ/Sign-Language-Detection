Developed a sign language detection system to improve communication and accessibility by converting gestures into text or speech. Created datasets with around 100 images for phrases such as "I love you," "thank you," "hello," "yes," and "no." Utilizing TensorFlow and OpenCV, implemented real-time detection with customizable gesture-emotion mappings. The system achieved high accuracy through comprehensive training and testing, significantly enhancing interaction and inclusivity for deaf individuals.
